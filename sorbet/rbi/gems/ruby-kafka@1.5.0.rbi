# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `ruby-kafka` gem.
# Please instead update this file by running `bin/tapioca gem ruby-kafka`.

# source://ruby-kafka//lib/kafka/version.rb#3
module Kafka
  class << self
    # source://ruby-kafka//lib/kafka.rb#362
    def new(seed_brokers = T.unsafe(nil), **options); end
  end
end

# source://ruby-kafka//lib/kafka/async_producer.rb#61
class Kafka::AsyncProducer
  # source://ruby-kafka//lib/kafka/async_producer.rb#73
  def initialize(sync_producer:, instrumenter:, logger:, max_queue_size: T.unsafe(nil), delivery_threshold: T.unsafe(nil), delivery_interval: T.unsafe(nil), max_retries: T.unsafe(nil), retry_backoff: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#133
  def deliver_messages; end

  # source://ruby-kafka//lib/kafka/async_producer.rb#105
  def produce(value, topic:, **options); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#146
  def shutdown; end

  private

  # source://ruby-kafka//lib/kafka/async_producer.rb#175
  def buffer_overflow(topic, message); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#158
  def ensure_threads_running!; end

  # source://ruby-kafka//lib/kafka/async_producer.rb#171
  def timer_thread_alive?; end

  # source://ruby-kafka//lib/kafka/async_producer.rb#167
  def worker_thread_alive?; end
end

# source://ruby-kafka//lib/kafka/async_producer.rb#183
class Kafka::AsyncProducer::Timer
  # source://ruby-kafka//lib/kafka/async_producer.rb#184
  def initialize(interval:, queue:); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#189
  def run; end
end

# source://ruby-kafka//lib/kafka/async_producer.rb#200
class Kafka::AsyncProducer::Worker
  # source://ruby-kafka//lib/kafka/async_producer.rb#201
  def initialize(queue:, producer:, delivery_threshold:, instrumenter:, logger:, max_retries: T.unsafe(nil), retry_backoff: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#211
  def run; end

  private

  # source://ruby-kafka//lib/kafka/async_producer.rb#283
  def deliver_messages; end

  # source://ruby-kafka//lib/kafka/async_producer.rb#226
  def do_loop; end

  # source://ruby-kafka//lib/kafka/async_producer.rb#264
  def produce(value, **kwargs); end

  # source://ruby-kafka//lib/kafka/async_producer.rb#291
  def threshold_reached?; end
end

# source://ruby-kafka//lib/kafka/broker.rb#8
class Kafka::Broker
  # source://ruby-kafka//lib/kafka/broker.rb#9
  def initialize(connection_builder:, host:, port:, logger:, node_id: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/broker.rb#185
  def add_offsets_to_txn(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#173
  def add_partitions_to_txn(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#18
  def address_match?(host, port); end

  # source://ruby-kafka//lib/kafka/broker.rb#137
  def alter_configs(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#155
  def api_versions; end

  # source://ruby-kafka//lib/kafka/broker.rb#83
  def commit_offsets(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#33
  def connected?; end

  # source://ruby-kafka//lib/kafka/broker.rb#143
  def create_partitions(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#119
  def create_topics(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#125
  def delete_topics(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#131
  def describe_configs(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#161
  def describe_groups(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#28
  def disconnect; end

  # source://ruby-kafka//lib/kafka/broker.rb#179
  def end_txn(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#51
  def fetch_messages(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#41
  def fetch_metadata(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#77
  def fetch_offsets(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#107
  def find_coordinator(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#113
  def heartbeat(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#167
  def init_producer_id(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#89
  def join_group(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#101
  def leave_group(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#149
  def list_groups; end

  # source://ruby-kafka//lib/kafka/broker.rb#61
  def list_offsets(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#71
  def produce(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#95
  def sync_group(**options); end

  # source://ruby-kafka//lib/kafka/broker.rb#23
  def to_s; end

  # source://ruby-kafka//lib/kafka/broker.rb#191
  def txn_offset_commit(**options); end

  private

  # source://ruby-kafka//lib/kafka/broker.rb#213
  def connection; end

  # source://ruby-kafka//lib/kafka/broker.rb#199
  def send_request(request); end
end

# source://ruby-kafka//lib/kafka/broker_info.rb#3
class Kafka::BrokerInfo
  # source://ruby-kafka//lib/kafka/broker_info.rb#6
  def initialize(node_id:, host:, port:); end

  # source://ruby-kafka//lib/kafka/broker_info.rb#4
  def host; end

  # source://ruby-kafka//lib/kafka/broker_info.rb#4
  def node_id; end

  # source://ruby-kafka//lib/kafka/broker_info.rb#4
  def port; end

  # source://ruby-kafka//lib/kafka/broker_info.rb#12
  def to_s; end
end

# source://ruby-kafka//lib/kafka.rb#76
class Kafka::BrokerNotAvailable < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/broker_pool.rb#6
class Kafka::BrokerPool
  # source://ruby-kafka//lib/kafka/broker_pool.rb#7
  def initialize(connection_builder:, logger:); end

  # source://ruby-kafka//lib/kafka/broker_pool.rb#34
  def close; end

  # source://ruby-kafka//lib/kafka/broker_pool.rb#13
  def connect(host, port, node_id: T.unsafe(nil)); end
end

# source://ruby-kafka//lib/kafka/broker_uri.rb#6
module Kafka::BrokerUri
  class << self
    # source://ruby-kafka//lib/kafka/broker_uri.rb#21
    def parse(str); end
  end
end

# source://ruby-kafka//lib/kafka/broker_uri.rb#7
Kafka::BrokerUri::DEFAULT_PORT = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/broker_uri.rb#8
Kafka::BrokerUri::URI_SCHEMES = T.let(T.unsafe(nil), Array)

# source://ruby-kafka//lib/kafka.rb#325
class Kafka::BufferOverflow < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/client.rb#21
class Kafka::Client
  # source://ruby-kafka//lib/kafka/client.rb#83
  def initialize(seed_brokers:, client_id: T.unsafe(nil), logger: T.unsafe(nil), connect_timeout: T.unsafe(nil), socket_timeout: T.unsafe(nil), ssl_ca_cert_file_path: T.unsafe(nil), ssl_ca_cert: T.unsafe(nil), ssl_client_cert: T.unsafe(nil), ssl_client_cert_key: T.unsafe(nil), ssl_client_cert_key_password: T.unsafe(nil), ssl_client_cert_chain: T.unsafe(nil), sasl_gssapi_principal: T.unsafe(nil), sasl_gssapi_keytab: T.unsafe(nil), sasl_plain_authzid: T.unsafe(nil), sasl_plain_username: T.unsafe(nil), sasl_plain_password: T.unsafe(nil), sasl_scram_username: T.unsafe(nil), sasl_scram_password: T.unsafe(nil), sasl_scram_mechanism: T.unsafe(nil), sasl_aws_msk_iam_access_key_id: T.unsafe(nil), sasl_aws_msk_iam_secret_key_id: T.unsafe(nil), sasl_aws_msk_iam_aws_region: T.unsafe(nil), sasl_aws_msk_iam_session_token: T.unsafe(nil), sasl_over_ssl: T.unsafe(nil), ssl_ca_certs_from_system: T.unsafe(nil), partitioner: T.unsafe(nil), sasl_oauth_token_provider: T.unsafe(nil), ssl_verify_hostname: T.unsafe(nil), resolve_seed_brokers: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#598
  def alter_configs(broker_id, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#675
  def alter_topic(name, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#792
  def apis; end

  # source://ruby-kafka//lib/kafka/client.rb#340
  def async_producer(delivery_interval: T.unsafe(nil), delivery_threshold: T.unsafe(nil), max_queue_size: T.unsafe(nil), max_retries: T.unsafe(nil), retry_backoff: T.unsafe(nil), **options); end

  # source://ruby-kafka//lib/kafka/client.rb#799
  def brokers; end

  # source://ruby-kafka//lib/kafka/client.rb#813
  def close; end

  # source://ruby-kafka//lib/kafka/client.rb#380
  def consumer(group_id:, session_timeout: T.unsafe(nil), rebalance_timeout: T.unsafe(nil), offset_commit_interval: T.unsafe(nil), offset_commit_threshold: T.unsafe(nil), heartbeat_interval: T.unsafe(nil), offset_retention_time: T.unsafe(nil), fetcher_max_queue_size: T.unsafe(nil), refresh_topic_interval: T.unsafe(nil), interceptors: T.unsafe(nil), assignment_strategy: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#806
  def controller_broker; end

  # source://ruby-kafka//lib/kafka/client.rb#703
  def create_partitions_for(name, num_partitions: T.unsafe(nil), timeout: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#622
  def create_topic(name, num_partitions: T.unsafe(nil), replication_factor: T.unsafe(nil), timeout: T.unsafe(nil), config: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#638
  def delete_topic(name, timeout: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#163
  def deliver_message(value, topic:, key: T.unsafe(nil), headers: T.unsafe(nil), partition: T.unsafe(nil), partition_key: T.unsafe(nil), retries: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#589
  def describe_configs(broker_id, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#683
  def describe_group(group_id); end

  # source://ruby-kafka//lib/kafka/client.rb#657
  def describe_topic(name, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#558
  def each_message(topic:, start_from_beginning: T.unsafe(nil), max_wait_time: T.unsafe(nil), min_bytes: T.unsafe(nil), max_bytes: T.unsafe(nil), &block); end

  # source://ruby-kafka//lib/kafka/client.rb#691
  def fetch_group_offsets(group_id); end

  # source://ruby-kafka//lib/kafka/client.rb#510
  def fetch_messages(topic:, partition:, offset: T.unsafe(nil), max_wait_time: T.unsafe(nil), min_bytes: T.unsafe(nil), max_bytes: T.unsafe(nil), retries: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#725
  def groups; end

  # source://ruby-kafka//lib/kafka/client.rb#729
  def has_topic?(topic); end

  # source://ruby-kafka//lib/kafka/client.rb#758
  def last_offset_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/client.rb#774
  def last_offsets_for(*topics); end

  # source://ruby-kafka//lib/kafka/client.rb#739
  def partitions_for(topic); end

  # source://ruby-kafka//lib/kafka/client.rb#278
  def producer(compression_codec: T.unsafe(nil), compression_threshold: T.unsafe(nil), ack_timeout: T.unsafe(nil), required_acks: T.unsafe(nil), max_retries: T.unsafe(nil), retry_backoff: T.unsafe(nil), max_buffer_size: T.unsafe(nil), max_buffer_bytesize: T.unsafe(nil), idempotent: T.unsafe(nil), transactional: T.unsafe(nil), transactional_id: T.unsafe(nil), transactional_timeout: T.unsafe(nil), interceptors: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#747
  def replica_count_for(topic); end

  # source://ruby-kafka//lib/kafka/client.rb#788
  def supports_api?(api_key, version = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/client.rb#710
  def topics; end

  private

  # source://ruby-kafka//lib/kafka/client.rb#819
  def initialize_cluster; end

  # source://ruby-kafka//lib/kafka/client.rb#833
  def normalize_seed_brokers(seed_brokers); end
end

# source://ruby-kafka//lib/kafka/cluster.rb#13
class Kafka::Cluster
  # source://ruby-kafka//lib/kafka/cluster.rb#23
  def initialize(seed_brokers:, broker_pool:, logger:, resolve_seed_brokers: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#45
  def add_target_topics(topics); end

  # source://ruby-kafka//lib/kafka/cluster.rb#166
  def alter_configs(broker_id, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#271
  def alter_topic(name, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#64
  def api_info(api_key); end

  # source://ruby-kafka//lib/kafka/cluster.rb#79
  def apis; end

  # source://ruby-kafka//lib/kafka/cluster.rb#94
  def clear_target_topics; end

  # source://ruby-kafka//lib/kafka/cluster.rb#404
  def cluster_info; end

  # source://ruby-kafka//lib/kafka/cluster.rb#310
  def create_partitions_for(name, num_partitions:, timeout:); end

  # source://ruby-kafka//lib/kafka/cluster.rb#192
  def create_topic(name, num_partitions:, replication_factor:, timeout:, config:); end

  # source://ruby-kafka//lib/kafka/cluster.rb#233
  def delete_topic(name, timeout:); end

  # source://ruby-kafka//lib/kafka/cluster.rb#149
  def describe_configs(broker_id, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#289
  def describe_group(group_id); end

  # source://ruby-kafka//lib/kafka/cluster.rb#252
  def describe_topic(name, configs = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#400
  def disconnect; end

  # source://ruby-kafka//lib/kafka/cluster.rb#296
  def fetch_group_offsets(group_id); end

  # source://ruby-kafka//lib/kafka/cluster.rb#125
  def get_group_coordinator(group_id:); end

  # source://ruby-kafka//lib/kafka/cluster.rb#117
  def get_leader(topic, partition); end

  # source://ruby-kafka//lib/kafka/cluster.rb#135
  def get_transaction_coordinator(transactional_id:); end

  # source://ruby-kafka//lib/kafka/cluster.rb#391
  def list_groups; end

  # source://ruby-kafka//lib/kafka/cluster.rb#384
  def list_topics; end

  # source://ruby-kafka//lib/kafka/cluster.rb#99
  def mark_as_stale!; end

  # source://ruby-kafka//lib/kafka/cluster.rb#183
  def partitions_for(topic); end

  # source://ruby-kafka//lib/kafka/cluster.rb#103
  def refresh_metadata!; end

  # source://ruby-kafka//lib/kafka/cluster.rb#108
  def refresh_metadata_if_necessary!; end

  # source://ruby-kafka//lib/kafka/cluster.rb#372
  def resolve_offset(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/cluster.rb#330
  def resolve_offsets(topic, partitions, offset); end

  # source://ruby-kafka//lib/kafka/cluster.rb#68
  def supports_api?(api_key, version = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/cluster.rb#376
  def topics; end

  private

  # source://ruby-kafka//lib/kafka/cluster.rb#463
  def connect_to_broker(broker_id); end

  # source://ruby-kafka//lib/kafka/cluster.rb#469
  def controller_broker; end

  # source://ruby-kafka//lib/kafka/cluster.rb#422
  def fetch_cluster_info; end

  # source://ruby-kafka//lib/kafka/cluster.rb#473
  def get_coordinator(coordinator_type, coordinator_key); end

  # source://ruby-kafka//lib/kafka/cluster.rb#410
  def get_leader_id(topic, partition); end

  # source://ruby-kafka//lib/kafka/cluster.rb#457
  def random_broker; end
end

# source://ruby-kafka//lib/kafka.rb#196
class Kafka::ClusterAuthorizationFailed < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/compression.rb#9
module Kafka::Compression
  class << self
    # source://ruby-kafka//lib/kafka/compression.rb#21
    def codecs; end

    # source://ruby-kafka//lib/kafka/compression.rb#25
    def find_codec(name); end

    # source://ruby-kafka//lib/kafka/compression.rb#35
    def find_codec_by_id(codec_id); end
  end
end

# source://ruby-kafka//lib/kafka/compression.rb#17
Kafka::Compression::CODECS_BY_ID = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/compression.rb#10
Kafka::Compression::CODECS_BY_NAME = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/compressor.rb#20
class Kafka::Compressor
  # source://ruby-kafka//lib/kafka/compressor.rb#26
  def initialize(instrumenter:, codec_name: T.unsafe(nil), threshold: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/compressor.rb#21
  def codec; end

  # source://ruby-kafka//lib/kafka/compressor.rb#37
  def compress(record_batch, offset: T.unsafe(nil)); end

  private

  # source://ruby-kafka//lib/kafka/compressor.rb#48
  def compress_message_set(message_set, offset); end

  # source://ruby-kafka//lib/kafka/compressor.rb#69
  def compress_record_batch(record_batch); end
end

# source://ruby-kafka//lib/kafka.rb#290
class Kafka::ConcurrentTransactionError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/connection.rb#29
class Kafka::Connection
  # source://ruby-kafka//lib/kafka/connection.rb#53
  def initialize(host:, port:, client_id:, logger:, instrumenter:, connect_timeout: T.unsafe(nil), socket_timeout: T.unsafe(nil), ssl_context: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/connection.rb#74
  def close; end

  # source://ruby-kafka//lib/kafka/connection.rb#37
  def decoder; end

  # source://ruby-kafka//lib/kafka/connection.rb#36
  def encoder; end

  # source://ruby-kafka//lib/kafka/connection.rb#70
  def open?; end

  # source://ruby-kafka//lib/kafka/connection.rb#86
  def send_request(request); end

  # source://ruby-kafka//lib/kafka/connection.rb#66
  def to_s; end

  private

  # source://ruby-kafka//lib/kafka/connection.rb#150
  def idle?; end

  # source://ruby-kafka//lib/kafka/connection.rb#126
  def open; end

  # source://ruby-kafka//lib/kafka/connection.rb#185
  def read_response(response_class, notification); end

  # source://ruby-kafka//lib/kafka/connection.rb#205
  def wait_for_response(response_class, notification); end

  # source://ruby-kafka//lib/kafka/connection.rb#159
  def write_request(request, notification); end
end

# source://ruby-kafka//lib/kafka/connection.rb#31
Kafka::Connection::CONNECT_TIMEOUT = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/connection.rb#34
Kafka::Connection::IDLE_TIMEOUT = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/connection.rb#30
Kafka::Connection::SOCKET_TIMEOUT = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/connection_builder.rb#4
class Kafka::ConnectionBuilder
  # source://ruby-kafka//lib/kafka/connection_builder.rb#5
  def initialize(client_id:, logger:, instrumenter:, connect_timeout:, socket_timeout:, ssl_context:, sasl_authenticator:); end

  # source://ruby-kafka//lib/kafka/connection_builder.rb#15
  def build_connection(host, port); end
end

# source://ruby-kafka//lib/kafka.rb#318
class Kafka::ConnectionError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/consumer.rb#46
class Kafka::Consumer
  # source://ruby-kafka//lib/kafka/consumer.rb#48
  def initialize(cluster:, logger:, instrumenter:, group:, fetcher:, offset_manager:, session_timeout:, heartbeat:, refresh_topic_interval: T.unsafe(nil), interceptors: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#387
  def commit_offsets; end

  # source://ruby-kafka//lib/kafka/consumer.rb#304
  def each_batch(min_bytes: T.unsafe(nil), max_bytes: T.unsafe(nil), max_wait_time: T.unsafe(nil), automatically_mark_as_processed: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#215
  def each_message(min_bytes: T.unsafe(nil), max_bytes: T.unsafe(nil), max_wait_time: T.unsafe(nil), automatically_mark_as_processed: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#391
  def mark_message_as_processed(message); end

  # source://ruby-kafka//lib/kafka/consumer.rb#152
  def pause(topic, partition, timeout: T.unsafe(nil), max_timeout: T.unsafe(nil), exponential_backoff: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#183
  def paused?(topic, partition); end

  # source://ruby-kafka//lib/kafka/consumer.rb#170
  def resume(topic, partition); end

  # source://ruby-kafka//lib/kafka/consumer.rb#383
  def seek(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/consumer.rb#399
  def send_heartbeat; end

  # source://ruby-kafka//lib/kafka/consumer.rb#395
  def send_heartbeat_if_necessary; end

  # source://ruby-kafka//lib/kafka/consumer.rb#128
  def stop; end

  # source://ruby-kafka//lib/kafka/consumer.rb#110
  def subscribe(topic_or_regex, default_offset: T.unsafe(nil), start_from_beginning: T.unsafe(nil), max_bytes_per_partition: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#395
  def trigger_heartbeat; end

  # source://ruby-kafka//lib/kafka/consumer.rb#399
  def trigger_heartbeat!; end

  private

  # source://ruby-kafka//lib/kafka/consumer.rb#592
  def clear_current_offsets(excluding: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#630
  def cluster_topics; end

  # source://ruby-kafka//lib/kafka/consumer.rb#409
  def consumer_loop; end

  # source://ruby-kafka//lib/kafka/consumer.rb#542
  def fetch_batches; end

  # source://ruby-kafka//lib/kafka/consumer.rb#470
  def join_group; end

  # source://ruby-kafka//lib/kafka/consumer.rb#455
  def make_final_offsets_commit!(attempts = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/consumer.rb#580
  def pause_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/consumer.rb#534
  def refresh_topic_list_if_enabled; end

  # source://ruby-kafka//lib/kafka/consumer.rb#517
  def resume_paused_partitions!; end

  # source://ruby-kafka//lib/kafka/consumer.rb#584
  def running?; end

  # source://ruby-kafka//lib/kafka/consumer.rb#600
  def scan_for_subscribing; end

  # source://ruby-kafka//lib/kafka/consumer.rb#505
  def seek_to_next(topic, partition); end

  # source://ruby-kafka//lib/kafka/consumer.rb#588
  def shutting_down?; end

  # source://ruby-kafka//lib/kafka/consumer.rb#613
  def subscribe_to_regex(topic_regex, default_offset, start_from_beginning, max_bytes_per_partition); end

  # source://ruby-kafka//lib/kafka/consumer.rb#619
  def subscribe_to_topic(topic, default_offset, start_from_beginning, max_bytes_per_partition); end
end

# source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#6
class Kafka::ConsumerGroup
  # source://ruby-kafka//lib/kafka/consumer_group.rb#11
  def initialize(cluster:, logger:, group_id:, session_timeout:, rebalance_timeout:, retention_time:, instrumenter:, assignment_strategy:); end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#9
  def assigned_partitions; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#39
  def assigned_to?(topic, partition); end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#86
  def commit_offsets(offsets); end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#79
  def fetch_offsets; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#9
  def generation_id; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#9
  def group_id; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#105
  def heartbeat; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#47
  def join; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#67
  def leave; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#43
  def member?; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#30
  def subscribe(topic); end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#35
  def subscribed_partitions; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#133
  def to_s; end

  private

  # source://ruby-kafka//lib/kafka/consumer_group.rb#221
  def coordinator; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#182
  def group_leader?; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#144
  def join_group; end

  # source://ruby-kafka//lib/kafka/consumer_group.rb#186
  def synchronize; end
end

# source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#9
class Kafka::ConsumerGroup::Assignor
  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#15
  def initialize(cluster:, strategy:); end

  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#35
  def assign(members:, topics:); end

  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#20
  def protocol_name; end

  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#24
  def user_data; end
end

# source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#10
class Kafka::ConsumerGroup::Assignor::Partition < ::Struct
  def partition_id; end

  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#10
  def partition_id=(_); end

  def topic; end

  # source://ruby-kafka//lib/kafka/consumer_group/assignor.rb#10
  def topic=(_); end

  class << self
    def [](*_arg0); end
    def inspect; end
    def members; end
    def new(*_arg0); end
  end
end

# source://ruby-kafka//lib/kafka.rb#108
class Kafka::CoordinatorLoadInProgress < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#113
class Kafka::CoordinatorNotAvailable < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#41
class Kafka::CorruptMessage < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/crc32_hash.rb#6
class Kafka::Crc32Hash
  # source://ruby-kafka//lib/kafka/crc32_hash.rb#11
  def hash(value); end

  # source://ruby-kafka//lib/kafka/crc32_hash.rb#9
  def load; end
end

# source://ruby-kafka//lib/kafka/instrumenter.rb#28
class Kafka::DecoratingInstrumenter
  # source://ruby-kafka//lib/kafka/instrumenter.rb#29
  def initialize(backend, extra_payload = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/instrumenter.rb#34
  def instrument(event_name, payload = T.unsafe(nil), &block); end
end

# source://ruby-kafka//lib/kafka.rb#329
class Kafka::DeliveryFailed < ::Kafka::Error
  # source://ruby-kafka//lib/kafka.rb#332
  def initialize(message, failed_messages); end

  # source://ruby-kafka//lib/kafka.rb#330
  def failed_messages; end
end

# source://ruby-kafka//lib/kafka/digest.rb#7
module Kafka::Digest
  class << self
    # source://ruby-kafka//lib/kafka/digest.rb#13
    def find_digest(name); end
  end
end

# source://ruby-kafka//lib/kafka/digest.rb#8
Kafka::Digest::FUNCTIONS_BY_NAME = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka.rb#265
class Kafka::DuplicateSequenceNumberError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#6
class Kafka::Error < ::StandardError; end

# source://ruby-kafka//lib/kafka.rb#351
class Kafka::FailedScramAuthentication < ::Kafka::SaslScramError; end

# source://ruby-kafka//lib/kafka.rb#345
class Kafka::FetchError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/fetch_operation.rb#23
class Kafka::FetchOperation
  # source://ruby-kafka//lib/kafka/fetch_operation.rb#24
  def initialize(cluster:, logger:, min_bytes: T.unsafe(nil), max_bytes: T.unsafe(nil), max_wait_time: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/fetch_operation.rb#51
  def execute; end

  # source://ruby-kafka//lib/kafka/fetch_operation.rb#37
  def fetch_from_partition(topic, partition, offset: T.unsafe(nil), max_bytes: T.unsafe(nil)); end
end

# source://ruby-kafka//lib/kafka/fetched_batch.rb#6
class Kafka::FetchedBatch
  # source://ruby-kafka//lib/kafka/fetched_batch.rb#25
  def initialize(topic:, partition:, highwater_mark_offset:, messages:, last_offset: T.unsafe(nil), leader_epoch: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#34
  def empty?; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#42
  def first_offset; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#20
  def highwater_mark_offset; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#14
  def last_offset; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#17
  def leader_epoch; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#23
  def messages; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#23
  def messages=(_arg0); end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#50
  def offset_lag; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#11
  def partition; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#8
  def topic; end

  # source://ruby-kafka//lib/kafka/fetched_batch.rb#38
  def unknown_last_offset?; end
end

# source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#6
class Kafka::FetchedBatchGenerator
  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#10
  def initialize(topic, fetched_partition, offset, logger:); end

  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#17
  def generate; end

  private

  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#110
  def abort_marker?(record_batch); end

  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#29
  def empty_fetched_batch; end

  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#39
  def extract_messages; end

  # source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#62
  def extract_records; end
end

# source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#8
Kafka::FetchedBatchGenerator::ABORTED_TRANSACTION_SIGNAL = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/fetched_batch_generator.rb#7
Kafka::FetchedBatchGenerator::COMMITTED_TRANSACTION_SIGNAL = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/fetched_message.rb#4
class Kafka::FetchedMessage
  # source://ruby-kafka//lib/kafka/fetched_message.rb#11
  def initialize(message:, topic:, partition:); end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#33
  def create_time; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#38
  def headers; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#43
  def is_control_record; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#23
  def key; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#28
  def offset; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#9
  def partition; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#6
  def topic; end

  # source://ruby-kafka//lib/kafka/fetched_message.rb#18
  def value; end
end

# source://ruby-kafka//lib/kafka/fetched_offset_resolver.rb#4
class Kafka::FetchedOffsetResolver
  # source://ruby-kafka//lib/kafka/fetched_offset_resolver.rb#5
  def initialize(logger:); end

  # source://ruby-kafka//lib/kafka/fetched_offset_resolver.rb#9
  def resolve!(broker, topics); end

  private

  # source://ruby-kafka//lib/kafka/fetched_offset_resolver.rb#29
  def filter_pending_topics(topics); end
end

# source://ruby-kafka//lib/kafka/fetcher.rb#6
class Kafka::Fetcher
  # source://ruby-kafka//lib/kafka/fetcher.rb#9
  def initialize(cluster:, logger:, instrumenter:, max_queue_size:, group:); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#48
  def configure(min_bytes:, max_bytes:, max_wait_time:); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#77
  def data?; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#7
  def max_wait_time; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#81
  def poll; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#7
  def queue; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#72
  def reset; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#44
  def seek(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#52
  def start; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#66
  def stop; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#40
  def subscribe(topic, max_bytes_per_partition:); end

  private

  # source://ruby-kafka//lib/kafka/fetcher.rb#97
  def current_reset_counter; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#184
  def fetch_batches; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#123
  def handle_configure(min_bytes, max_bytes, max_wait_time); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#129
  def handle_reset; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#149
  def handle_seek(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#134
  def handle_stop(*_arg0); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#144
  def handle_subscribe(topic, max_bytes_per_partition); end

  # source://ruby-kafka//lib/kafka/fetcher.rb#99
  def loop; end

  # source://ruby-kafka//lib/kafka/fetcher.rb#159
  def step; end
end

# source://ruby-kafka//lib/kafka.rb#192
class Kafka::GroupAuthorizationFailed < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/gzip_codec.rb#4
class Kafka::GzipCodec
  # source://ruby-kafka//lib/kafka/gzip_codec.rb#5
  def codec_id; end

  # source://ruby-kafka//lib/kafka/gzip_codec.rb#17
  def compress(data); end

  # source://ruby-kafka//lib/kafka/gzip_codec.rb#28
  def decompress(data); end

  # source://ruby-kafka//lib/kafka/gzip_codec.rb#13
  def load; end

  # source://ruby-kafka//lib/kafka/gzip_codec.rb#9
  def produce_api_min_version; end
end

# source://ruby-kafka//lib/kafka/heartbeat.rb#4
class Kafka::Heartbeat
  # source://ruby-kafka//lib/kafka/heartbeat.rb#5
  def initialize(group:, interval:, instrumenter:); end

  # source://ruby-kafka//lib/kafka/heartbeat.rb#21
  def trigger; end

  # source://ruby-kafka//lib/kafka/heartbeat.rb#12
  def trigger!; end
end

# source://ruby-kafka//lib/kafka.rb#339
class Kafka::HeartbeatError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#311
class Kafka::IdleConnection < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#154
class Kafka::IllegalGeneration < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#159
class Kafka::InconsistentGroupProtocol < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/instrumenter.rb#4
class Kafka::Instrumenter
  # source://ruby-kafka//lib/kafka/instrumenter.rb#7
  def initialize(default_payload = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/instrumenter.rb#17
  def instrument(event_name, payload = T.unsafe(nil), &block); end
end

# source://ruby-kafka//lib/kafka/instrumenter.rb#5
Kafka::Instrumenter::NAMESPACE = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka.rb#315
class Kafka::InsufficientDataMessage < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/interceptors.rb#6
class Kafka::Interceptors
  # source://ruby-kafka//lib/kafka/interceptors.rb#7
  def initialize(interceptors:, logger:); end

  # source://ruby-kafka//lib/kafka/interceptors.rb#21
  def call(intercepted); end
end

# source://ruby-kafka//lib/kafka.rb#184
class Kafka::InvalidCommitOffsetSize < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#236
class Kafka::InvalidConfig < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#164
class Kafka::InvalidGroupId < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#51
class Kafka::InvalidMessageSize < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#223
class Kafka::InvalidPartitions < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#270
class Kafka::InvalidProducerEpochError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#280
class Kafka::InvalidProducerIDMappingError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#232
class Kafka::InvalidReplicaAssignment < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#228
class Kafka::InvalidReplicationFactor < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#245
class Kafka::InvalidRequest < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#149
class Kafka::InvalidRequiredAcks < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#210
class Kafka::InvalidSaslState < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#174
class Kafka::InvalidSessionTimeout < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#201
class Kafka::InvalidTimestamp < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#125
class Kafka::InvalidTopic < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#285
class Kafka::InvalidTransactionTimeoutError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#275
class Kafka::InvalidTxnStateError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/lz4_codec.rb#4
class Kafka::LZ4Codec
  # source://ruby-kafka//lib/kafka/lz4_codec.rb#5
  def codec_id; end

  # source://ruby-kafka//lib/kafka/lz4_codec.rb#19
  def compress(data); end

  # source://ruby-kafka//lib/kafka/lz4_codec.rb#23
  def decompress(data); end

  # source://ruby-kafka//lib/kafka/lz4_codec.rb#13
  def load; end

  # source://ruby-kafka//lib/kafka/lz4_codec.rb#9
  def produce_api_min_version; end
end

# source://ruby-kafka//lib/kafka.rb#58
class Kafka::LeaderNotAvailable < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/message_buffer.rb#8
class Kafka::MessageBuffer
  include ::Enumerable

  # source://ruby-kafka//lib/kafka/message_buffer.rb#13
  def initialize; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#11
  def bytesize; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#74
  def clear; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#57
  def clear_messages(topic:, partition:); end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#28
  def concat(messages, topic:, partition:); end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#43
  def each; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#39
  def empty?; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#67
  def messages_for(topic:, partition:); end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#11
  def size; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#35
  def to_h; end

  # source://ruby-kafka//lib/kafka/message_buffer.rb#19
  def write(value:, key:, topic:, partition:, create_time: T.unsafe(nil), headers: T.unsafe(nil)); end

  private

  # source://ruby-kafka//lib/kafka/message_buffer.rb#82
  def buffer_for(topic, partition); end
end

# source://ruby-kafka//lib/kafka.rb#88
class Kafka::MessageSizeTooLarge < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#307
class Kafka::MessageTooLargeToRead < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/murmur2_hash.rb#4
class Kafka::Murmur2Hash
  # source://ruby-kafka//lib/kafka/murmur2_hash.rb#13
  def hash(value); end

  # source://ruby-kafka//lib/kafka/murmur2_hash.rb#7
  def load; end
end

# source://ruby-kafka//lib/kafka/murmur2_hash.rb#5
Kafka::Murmur2Hash::SEED = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka.rb#103
class Kafka::NetworkException < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#303
class Kafka::NoPartitionsToFetchFrom < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#321
class Kafka::NoSuchBroker < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#241
class Kafka::NotController < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#118
class Kafka::NotCoordinatorForGroup < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#137
class Kafka::NotEnoughReplicas < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#143
class Kafka::NotEnoughReplicasAfterAppend < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#65
class Kafka::NotLeaderForPartition < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#342
class Kafka::OffsetCommitError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/offset_manager.rb#7
class Kafka::OffsetManager
  # source://ruby-kafka//lib/kafka/offset_manager.rb#12
  def initialize(cluster:, group:, fetcher:, logger:, commit_interval:, commit_threshold:, offset_retention_time:); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#160
  def clear_offsets; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#174
  def clear_offsets_excluding(excluded); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#131
  def commit_offsets(recommit = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#150
  def commit_offsets_if_necessary; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#52
  def mark_as_processed(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#106
  def next_offset_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#94
  def seek_to(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#79
  def seek_to_default(topic, partition); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#39
  def set_default_offset(topic, default_offset); end

  private

  # source://ruby-kafka//lib/kafka/offset_manager.rb#189
  def clear_resolved_offset(topic); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#249
  def commit_threshold_reached?; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#245
  def commit_timeout_reached?; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#217
  def committed_offset_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#213
  def committed_offsets; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#198
  def fetch_resolved_offsets(topic); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#221
  def offsets_to_commit(recommit = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#231
  def offsets_to_recommit; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#253
  def prettify_offsets(offsets); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#241
  def recommit_timeout_reached?; end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#193
  def resolve_offset(topic, partition); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#205
  def seconds_since(time); end

  # source://ruby-kafka//lib/kafka/offset_manager.rb#209
  def seconds_since_last_commit; end
end

# source://ruby-kafka//lib/kafka/offset_manager.rb#10
Kafka::OffsetManager::DEFAULT_RETENTION_TIME = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka.rb#98
class Kafka::OffsetMetadataTooLarge < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#35
class Kafka::OffsetOutOfRange < ::Kafka::ProtocolError
  # source://ruby-kafka//lib/kafka.rb#36
  def offset; end

  # source://ruby-kafka//lib/kafka.rb#36
  def offset=(_arg0); end

  # source://ruby-kafka//lib/kafka.rb#36
  def partition; end

  # source://ruby-kafka//lib/kafka.rb#36
  def partition=(_arg0); end

  # source://ruby-kafka//lib/kafka.rb#36
  def topic; end

  # source://ruby-kafka//lib/kafka.rb#36
  def topic=(_arg0); end
end

# source://ruby-kafka//lib/kafka.rb#260
class Kafka::OutOfOrderSequenceNumberError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/partitioner.rb#8
class Kafka::Partitioner
  # source://ruby-kafka//lib/kafka/partitioner.rb#11
  def initialize(hash_function: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/partitioner.rb#27
  def call(partition_count, message); end
end

# source://ruby-kafka//lib/kafka/pause.rb#11
class Kafka::Pause
  # source://ruby-kafka//lib/kafka/pause.rb#12
  def initialize(clock: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/pause.rb#66
  def expired?; end

  # source://ruby-kafka//lib/kafka/pause.rb#32
  def pause!(timeout: T.unsafe(nil), max_timeout: T.unsafe(nil), exponential_backoff: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/pause.rb#57
  def pause_duration; end

  # source://ruby-kafka//lib/kafka/pause.rb#52
  def paused?; end

  # source://ruby-kafka//lib/kafka/pause.rb#75
  def reset!; end

  # source://ruby-kafka//lib/kafka/pause.rb#44
  def resume!; end

  private

  # source://ruby-kafka//lib/kafka/pause.rb#81
  def ends_at; end
end

# source://ruby-kafka//lib/kafka/pending_message.rb#4
class Kafka::PendingMessage
  # source://ruby-kafka//lib/kafka/pending_message.rb#7
  def initialize(value:, key:, topic:, partition:, partition_key:, create_time:, headers: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/pending_message.rb#18
  def ==(other); end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def bytesize; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def create_time; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def headers; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def key; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def partition; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def partition_key; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def topic; end

  # source://ruby-kafka//lib/kafka/pending_message.rb#5
  def value; end
end

# source://ruby-kafka//lib/kafka/pending_message_queue.rb#5
class Kafka::PendingMessageQueue
  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#8
  def initialize; end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#6
  def bytesize; end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#22
  def clear; end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#37
  def each(&block); end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#18
  def empty?; end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#28
  def replace(messages); end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#6
  def size; end

  # source://ruby-kafka//lib/kafka/pending_message_queue.rb#12
  def write(message); end
end

# source://ruby-kafka//lib/kafka.rb#255
class Kafka::PolicyViolation < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#10
class Kafka::ProcessingError < ::Kafka::Error
  # source://ruby-kafka//lib/kafka.rb#13
  def initialize(topic, partition, offset); end

  # source://ruby-kafka//lib/kafka.rb#11
  def offset; end

  # source://ruby-kafka//lib/kafka.rb#11
  def partition; end

  # source://ruby-kafka//lib/kafka.rb#11
  def topic; end
end

# source://ruby-kafka//lib/kafka/produce_operation.rb#32
class Kafka::ProduceOperation
  # source://ruby-kafka//lib/kafka/produce_operation.rb#33
  def initialize(cluster:, transaction_manager:, buffer:, compressor:, required_acks:, ack_timeout:, logger:, instrumenter:); end

  # source://ruby-kafka//lib/kafka/produce_operation.rb#44
  def execute; end

  private

  # source://ruby-kafka//lib/kafka/produce_operation.rb#143
  def handle_response(broker, response, records_for_topics); end

  # source://ruby-kafka//lib/kafka/produce_operation.rb#71
  def send_buffered_messages; end
end

# source://ruby-kafka//lib/kafka/producer.rb#130
class Kafka::Producer
  # source://ruby-kafka//lib/kafka/producer.rb#133
  def initialize(cluster:, transaction_manager:, logger:, instrumenter:, compressor:, ack_timeout:, required_acks:, max_retries:, retry_backoff:, max_buffer_size:, max_buffer_bytesize:, partitioner:, interceptors: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/producer.rb#337
  def abort_transaction; end

  # source://ruby-kafka//lib/kafka/producer.rb#313
  def begin_transaction; end

  # source://ruby-kafka//lib/kafka/producer.rb#275
  def buffer_bytesize; end

  # source://ruby-kafka//lib/kafka/producer.rb#271
  def buffer_size; end

  # source://ruby-kafka//lib/kafka/producer.rb#282
  def clear_buffer; end

  # source://ruby-kafka//lib/kafka/producer.rb#324
  def commit_transaction; end

  # source://ruby-kafka//lib/kafka/producer.rb#250
  def deliver_messages; end

  # source://ruby-kafka//lib/kafka/producer.rb#299
  def init_transactions; end

  # source://ruby-kafka//lib/kafka/producer.rb#195
  def produce(value, topic:, key: T.unsafe(nil), headers: T.unsafe(nil), partition: T.unsafe(nil), partition_key: T.unsafe(nil), create_time: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/producer.rb#351
  def send_offsets_to_transaction(batch:, group_id:); end

  # source://ruby-kafka//lib/kafka/producer.rb#290
  def shutdown; end

  # source://ruby-kafka//lib/kafka/producer.rb#160
  def to_s; end

  # source://ruby-kafka//lib/kafka/producer.rb#368
  def transaction; end

  private

  # source://ruby-kafka//lib/kafka/producer.rb#446
  def assign_partitions!; end

  # source://ruby-kafka//lib/kafka/producer.rb#496
  def buffer_messages; end

  # source://ruby-kafka//lib/kafka/producer.rb#520
  def buffer_overflow(topic, message); end

  # source://ruby-kafka//lib/kafka/producer.rb#382
  def deliver_messages_with_retries(notification); end

  # source://ruby-kafka//lib/kafka/producer.rb#442
  def pretty_partitions; end
end

# source://ruby-kafka//lib/kafka/producer.rb#131
class Kafka::Producer::AbortTransaction < ::StandardError; end

# source://ruby-kafka//lib/kafka/protocol/request_message.rb#4
module Kafka::Protocol
  class << self
    # source://ruby-kafka//lib/kafka/protocol.rb#170
    def api_name(api_key); end

    # source://ruby-kafka//lib/kafka/protocol.rb#156
    def handle_error(error_code, error_message = T.unsafe(nil)); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#36
Kafka::Protocol::ADD_OFFSETS_TO_TXN_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#35
Kafka::Protocol::ADD_PARTITIONS_TO_TXN_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#40
Kafka::Protocol::ALTER_CONFIGS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#44
Kafka::Protocol::APIS = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/protocol.rb#31
Kafka::Protocol::API_VERSIONS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_request.rb#5
class Kafka::Protocol::AddOffsetsToTxnRequest
  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_request.rb#6
  def initialize(producer_id:, producer_epoch:, group_id:, transactional_id: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_request.rb#13
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_request.rb#21
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_request.rb#17
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_response.rb#5
class Kafka::Protocol::AddOffsetsToTxnResponse
  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_response.rb#9
  def initialize(error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_response.rb#7
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/add_offsets_to_txn_response.rb#13
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_request.rb#5
class Kafka::Protocol::AddPartitionsToTxnRequest
  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_request.rb#6
  def initialize(producer_id:, producer_epoch:, topics:, transactional_id: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_request.rb#13
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_request.rb#21
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_request.rb#17
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#5
class Kafka::Protocol::AddPartitionsToTxnResponse
  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#26
  def initialize(errors:); end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#24
  def errors; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#30
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#6
class Kafka::Protocol::AddPartitionsToTxnResponse::PartitionError
  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#9
  def initialize(partition:, error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#7
  def partition; end
end

# source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#15
class Kafka::Protocol::AddPartitionsToTxnResponse::TopicPartitionsError
  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#18
  def initialize(topic:, partitions:); end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#16
  def partitions; end

  # source://ruby-kafka//lib/kafka/protocol/add_partitions_to_txn_response.rb#16
  def topic; end
end

# source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#6
class Kafka::Protocol::AlterConfigsRequest
  # source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#7
  def initialize(resources:); end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#23
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_request.rb#19
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#5
class Kafka::Protocol::AlterConfigsResponse
  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#19
  def initialize(throttle_time_ms:, resources:); end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#17
  def resources; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#24
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#6
class Kafka::Protocol::AlterConfigsResponse::ResourceDescription
  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#9
  def initialize(name:, type:, error_code:, error_message:); end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#7
  def error_message; end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#7
  def name; end

  # source://ruby-kafka//lib/kafka/protocol/alter_configs_response.rb#7
  def type; end
end

# source://ruby-kafka//lib/kafka/protocol/api_versions_request.rb#6
class Kafka::Protocol::ApiVersionsRequest
  # source://ruby-kafka//lib/kafka/protocol/api_versions_request.rb#7
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_request.rb#11
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_request.rb#15
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#6
class Kafka::Protocol::ApiVersionsResponse
  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#33
  def initialize(error_code:, apis:); end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#31
  def apis; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#31
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#38
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#7
class Kafka::Protocol::ApiVersionsResponse::ApiInfo
  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#10
  def initialize(api_key:, min_version:, max_version:); end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#8
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#14
  def api_name; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#26
  def inspect; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#8
  def max_version; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#8
  def min_version; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#22
  def to_s; end

  # source://ruby-kafka//lib/kafka/protocol/api_versions_response.rb#18
  def version_supported?(version); end
end

# source://ruby-kafka//lib/kafka/protocol.rb#147
Kafka::Protocol::COORDINATOR_TYPE_GROUP = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#148
Kafka::Protocol::COORDINATOR_TYPE_TRANSACTION = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#41
Kafka::Protocol::CREATE_PARTITIONS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#32
Kafka::Protocol::CREATE_TOPICS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/consumer_group_protocol.rb#5
class Kafka::Protocol::ConsumerGroupProtocol
  # source://ruby-kafka//lib/kafka/protocol/consumer_group_protocol.rb#6
  def initialize(topics:, version: T.unsafe(nil), user_data: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/consumer_group_protocol.rb#12
  def encode(encoder); end
end

# source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#6
class Kafka::Protocol::CreatePartitionsRequest
  # source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#7
  def initialize(topics:, timeout:); end

  # source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#23
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/create_partitions_request.rb#19
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/create_partitions_response.rb#6
class Kafka::Protocol::CreatePartitionsResponse
  # source://ruby-kafka//lib/kafka/protocol/create_partitions_response.rb#9
  def initialize(throttle_time_ms:, errors:); end

  # source://ruby-kafka//lib/kafka/protocol/create_partitions_response.rb#7
  def errors; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/create_partitions_response.rb#14
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#6
class Kafka::Protocol::CreateTopicsRequest
  # source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#7
  def initialize(topics:, timeout:); end

  # source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#23
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/create_topics_request.rb#19
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/create_topics_response.rb#6
class Kafka::Protocol::CreateTopicsResponse
  # source://ruby-kafka//lib/kafka/protocol/create_topics_response.rb#9
  def initialize(errors:); end

  # source://ruby-kafka//lib/kafka/protocol/create_topics_response.rb#7
  def errors; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/create_topics_response.rb#13
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#33
Kafka::Protocol::DELETE_TOPICS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#39
Kafka::Protocol::DESCRIBE_CONFIGS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#28
Kafka::Protocol::DESCRIBE_GROUPS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/decoder.rb#8
class Kafka::Protocol::Decoder
  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#16
  def initialize(io); end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#77
  def array(&block); end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#37
  def boolean; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#135
  def bytes; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#20
  def eof?; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#51
  def int16; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#58
  def int32; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#65
  def int64; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#44
  def int8; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#27
  def peek(offset, length); end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#162
  def read(number_of_bytes); end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#94
  def string; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#121
  def varint; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#86
  def varint_array(&block); end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#148
  def varint_bytes; end

  # source://ruby-kafka//lib/kafka/protocol/decoder.rb#107
  def varint_string; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/decoder.rb#9
    def from_string(str); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#6
class Kafka::Protocol::DeleteTopicsRequest
  # source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#7
  def initialize(topics:, timeout:); end

  # source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#23
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/delete_topics_request.rb#19
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/delete_topics_response.rb#6
class Kafka::Protocol::DeleteTopicsResponse
  # source://ruby-kafka//lib/kafka/protocol/delete_topics_response.rb#9
  def initialize(errors:); end

  # source://ruby-kafka//lib/kafka/protocol/delete_topics_response.rb#7
  def errors; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/delete_topics_response.rb#13
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#6
class Kafka::Protocol::DescribeConfigsRequest
  # source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#7
  def initialize(resources:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#23
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_request.rb#19
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#5
class Kafka::Protocol::DescribeConfigsResponse
  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#32
  def initialize(throttle_time_ms:, resources:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#30
  def resources; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#37
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#18
class Kafka::Protocol::DescribeConfigsResponse::ConfigEntry
  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#21
  def initialize(name:, value:, read_only:, is_default:, is_sensitive:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#19
  def is_default; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#19
  def is_sensitive; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#19
  def name; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#19
  def read_only; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#19
  def value; end
end

# source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#6
class Kafka::Protocol::DescribeConfigsResponse::ResourceDescription
  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#9
  def initialize(name:, type:, error_code:, error_message:, configs:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#7
  def configs; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#7
  def error_message; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#7
  def name; end

  # source://ruby-kafka//lib/kafka/protocol/describe_configs_response.rb#7
  def type; end
end

# source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#5
class Kafka::Protocol::DescribeGroupsRequest
  # source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#6
  def initialize(group_ids:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#10
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#14
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#22
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_request.rb#18
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#5
class Kafka::Protocol::DescribeGroupsResponse
  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#32
  def initialize(groups:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#30
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#30
  def groups; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#36
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#6
class Kafka::Protocol::DescribeGroupsResponse::Group
  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#9
  def initialize(error_code:, group_id:, protocol_type:, protocol:, state:, members:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#7
  def group_id; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#7
  def members; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#7
  def protocol; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#7
  def state; end
end

# source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#19
class Kafka::Protocol::DescribeGroupsResponse::Member
  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#22
  def initialize(member_id:, client_id:, client_host:, member_assignment:); end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#20
  def client_host; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#20
  def client_id; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#20
  def member_assignment; end

  # source://ruby-kafka//lib/kafka/protocol/describe_groups_response.rb#20
  def member_id; end
end

# source://ruby-kafka//lib/kafka/protocol.rb#37
Kafka::Protocol::END_TXN_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#70
Kafka::Protocol::ERRORS = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/protocol/encoder.rb#9
class Kafka::Protocol::Encoder
  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#13
  def initialize(io); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#22
  def write(bytes); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#76
  def write_array(array, &block); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#32
  def write_boolean(boolean); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#148
  def write_bytes(bytes); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#48
  def write_int16(int); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#56
  def write_int32(int); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#64
  def write_int64(int); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#40
  def write_int8(int); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#104
  def write_string(string); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#131
  def write_varint(int); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#91
  def write_varint_array(array, &block); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#161
  def write_varint_bytes(bytes); end

  # source://ruby-kafka//lib/kafka/protocol/encoder.rb#117
  def write_varint_string(string); end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/encoder.rb#174
    def encode_with(object); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/end_txn_request.rb#5
class Kafka::Protocol::EndTxnRequest
  # source://ruby-kafka//lib/kafka/protocol/end_txn_request.rb#6
  def initialize(transactional_id:, producer_id:, producer_epoch:, transaction_result:); end

  # source://ruby-kafka//lib/kafka/protocol/end_txn_request.rb#13
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/end_txn_request.rb#21
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/end_txn_request.rb#17
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/end_txn_response.rb#5
class Kafka::Protocol::EndTxnResposne
  # source://ruby-kafka//lib/kafka/protocol/end_txn_response.rb#8
  def initialize(error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/end_txn_response.rb#6
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/end_txn_response.rb#12
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#18
Kafka::Protocol::FETCH_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#23
Kafka::Protocol::FIND_COORDINATOR_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#21
class Kafka::Protocol::FetchRequest
  # source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#28
  def initialize(max_wait_time:, min_bytes:, max_bytes:, topics:); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#36
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#40
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#48
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#44
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#23
Kafka::Protocol::FetchRequest::ISOLATION_READ_COMMITTED = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/fetch_request.rb#22
Kafka::Protocol::FetchRequest::ISOLATION_READ_UNCOMMITTED = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#26
class Kafka::Protocol::FetchResponse
  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#64
  def initialize(topics: T.unsafe(nil), throttle_time_ms: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#62
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#69
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#53
class Kafka::Protocol::FetchResponse::AbortedTransaction
  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#56
  def initialize(producer_id:, first_offset:); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#54
  def first_offset; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#54
  def producer_id; end
end

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#30
class Kafka::Protocol::FetchResponse::FetchedPartition
  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#34
  def initialize(partition:, error_code:, highwater_mark_offset:, last_stable_offset:, aborted_transactions:, messages:); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#32
  def aborted_transactions; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#31
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#32
  def highwater_mark_offset; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#32
  def last_stable_offset; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#32
  def messages; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#31
  def partition; end
end

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#44
class Kafka::Protocol::FetchResponse::FetchedTopic
  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#47
  def initialize(name:, partitions:); end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#45
  def name; end

  # source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#45
  def partitions; end
end

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#28
Kafka::Protocol::FetchResponse::MAGIC_BYTE_LENGTH = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/fetch_response.rb#27
Kafka::Protocol::FetchResponse::MAGIC_BYTE_OFFSET = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#5
class Kafka::Protocol::FindCoordinatorRequest
  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#6
  def initialize(coordinator_key:, coordinator_type:); end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#15
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#19
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_request.rb#24
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#5
class Kafka::Protocol::FindCoordinatorResponse
  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#10
  def initialize(error_code:, error_message:, coordinator_id:, coordinator_host:, coordinator_port:); end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#8
  def coordinator_host; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#8
  def coordinator_id; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#8
  def coordinator_port; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#6
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#6
  def error_message; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/find_coordinator_response.rb#17
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#25
Kafka::Protocol::HEARTBEAT_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/heartbeat_request.rb#5
class Kafka::Protocol::HeartbeatRequest
  # source://ruby-kafka//lib/kafka/protocol/heartbeat_request.rb#6
  def initialize(group_id:, generation_id:, member_id:); end

  # source://ruby-kafka//lib/kafka/protocol/heartbeat_request.rb#12
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/heartbeat_request.rb#20
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/heartbeat_request.rb#16
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/heartbeat_response.rb#5
class Kafka::Protocol::HeartbeatResponse
  # source://ruby-kafka//lib/kafka/protocol/heartbeat_response.rb#8
  def initialize(error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/heartbeat_response.rb#6
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/heartbeat_response.rb#12
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#34
Kafka::Protocol::INIT_PRODUCER_ID_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/init_producer_id_request.rb#5
class Kafka::Protocol::InitProducerIDRequest
  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_request.rb#6
  def initialize(transactional_timeout:, transactional_id: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_request.rb#19
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_request.rb#15
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#5
class Kafka::Protocol::InitProducerIDResponse
  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#8
  def initialize(error_code:, producer_id:, producer_epoch:); end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#6
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#6
  def producer_epoch; end

  # source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#6
  def producer_id; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/init_producer_id_response.rb#14
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#24
Kafka::Protocol::JOIN_GROUP_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#7
class Kafka::Protocol::JoinGroupRequest
  # source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#10
  def initialize(group_id:, session_timeout:, rebalance_timeout:, member_id:, protocol_name:, topics: T.unsafe(nil), user_data: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#21
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#25
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#33
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#29
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/join_group_request.rb#8
Kafka::Protocol::JoinGroupRequest::PROTOCOL_TYPE = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#5
class Kafka::Protocol::JoinGroupResponse
  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#14
  def initialize(error_code:, generation_id:, group_protocol:, leader_id:, member_id:, members:); end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#8
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#10
  def generation_id; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#10
  def group_protocol; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#12
  def leader_id; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#12
  def member_id; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#12
  def members; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#23
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#6
class Kafka::Protocol::JoinGroupResponse::Metadata < ::Struct
  def topics; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#6
  def topics=(_); end

  def user_data; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#6
  def user_data=(_); end

  def version; end

  # source://ruby-kafka//lib/kafka/protocol/join_group_response.rb#6
  def version=(_); end

  class << self
    def [](*_arg0); end
    def inspect; end
    def members; end
    def new(*_arg0); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#26
Kafka::Protocol::LEAVE_GROUP_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#29
Kafka::Protocol::LIST_GROUPS_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#19
Kafka::Protocol::LIST_OFFSET_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/leave_group_request.rb#5
class Kafka::Protocol::LeaveGroupRequest
  # source://ruby-kafka//lib/kafka/protocol/leave_group_request.rb#6
  def initialize(group_id:, member_id:); end

  # source://ruby-kafka//lib/kafka/protocol/leave_group_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/leave_group_request.rb#19
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/leave_group_request.rb#15
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/leave_group_response.rb#5
class Kafka::Protocol::LeaveGroupResponse
  # source://ruby-kafka//lib/kafka/protocol/leave_group_response.rb#8
  def initialize(error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/leave_group_response.rb#6
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/leave_group_response.rb#12
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/list_groups_request.rb#5
class Kafka::Protocol::ListGroupsRequest
  # source://ruby-kafka//lib/kafka/protocol/list_groups_request.rb#6
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_request.rb#10
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_request.rb#18
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_request.rb#14
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#5
class Kafka::Protocol::ListGroupsResponse
  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#17
  def initialize(error_code:, groups:); end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#15
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#15
  def groups; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#22
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#6
class Kafka::Protocol::ListGroupsResponse::GroupEntry
  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#9
  def initialize(group_id:, protocol_type:); end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#7
  def group_id; end

  # source://ruby-kafka//lib/kafka/protocol/list_groups_response.rb#7
  def protocol_type; end
end

# source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#16
class Kafka::Protocol::ListOffsetRequest
  # source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#21
  def initialize(topics:); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#30
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#26
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#38
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#34
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#18
Kafka::Protocol::ListOffsetRequest::ISOLATION_READ_COMMITTED = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/list_offset_request.rb#17
Kafka::Protocol::ListOffsetRequest::ISOLATION_READ_UNCOMMITTED = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#18
class Kafka::Protocol::ListOffsetResponse
  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#41
  def initialize(topics:); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#45
  def offset_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#39
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#65
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#28
class Kafka::Protocol::ListOffsetResponse::PartitionOffsetInfo
  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#31
  def initialize(partition:, error_code:, timestamp:, offset:); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#29
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#29
  def offset; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#29
  def partition; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#29
  def timestamp; end
end

# source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#19
class Kafka::Protocol::ListOffsetResponse::TopicOffsetInfo
  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#22
  def initialize(name:, partition_offsets:); end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#20
  def name; end

  # source://ruby-kafka//lib/kafka/protocol/list_offset_response.rb#20
  def partition_offsets; end
end

# source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#5
class Kafka::Protocol::MemberAssignment
  # source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#8
  def initialize(version: T.unsafe(nil), topics: T.unsafe(nil), user_data: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#14
  def assign(topic, partitions); end

  # source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#19
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#6
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/member_assignment.rb#33
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/message.rb#19
class Kafka::Protocol::Message
  # source://ruby-kafka//lib/kafka/protocol/message.rb#26
  def initialize(value:, key: T.unsafe(nil), create_time: T.unsafe(nil), codec_id: T.unsafe(nil), offset: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#43
  def ==(other); end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#24
  def bytesize; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#22
  def codec_id; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#50
  def compressed?; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#24
  def create_time; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#55
  def decompress; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#36
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#110
  def headers; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#106
  def is_control_record; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#22
  def key; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#22
  def offset; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#22
  def value; end

  private

  # source://ruby-kafka//lib/kafka/protocol/message.rb#125
  def correct_offsets(messages); end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#145
  def encode_with_crc; end

  # source://ruby-kafka//lib/kafka/protocol/message.rb#158
  def encode_without_crc; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/message.rb#66
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/message.rb#20
Kafka::Protocol::Message::MAGIC_BYTE = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/message_set.rb#5
class Kafka::Protocol::MessageSet
  # source://ruby-kafka//lib/kafka/protocol/message_set.rb#8
  def initialize(messages: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/message_set.rb#16
  def ==(other); end

  # source://ruby-kafka//lib/kafka/protocol/message_set.rb#20
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/message_set.rb#6
  def messages; end

  # source://ruby-kafka//lib/kafka/protocol/message_set.rb#12
  def size; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/message_set.rb#28
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#5
class Kafka::Protocol::MetadataRequest
  # source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#10
  def initialize(topics: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#14
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#18
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#26
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_request.rb#22
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#35
class Kafka::Protocol::MetadataResponse
  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#75
  def initialize(brokers:, controller_id:, topics:); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#67
  def brokers; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#123
  def controller_broker; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#73
  def controller_id; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#115
  def find_broker(node_id); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#87
  def find_leader_id(topic, partition); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#127
  def partitions_for(topic_name); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#70
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#143
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#36
class Kafka::Protocol::MetadataResponse::PartitionMetadata
  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#41
  def initialize(partition_error_code:, partition_id:, leader:, replicas: T.unsafe(nil), isr: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#37
  def leader; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#39
  def partition_error_code; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#37
  def partition_id; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#37
  def replicas; end
end

# source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#50
class Kafka::Protocol::MetadataResponse::TopicMetadata
  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#59
  def initialize(topic_name:, partitions:, topic_error_code: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#55
  def partitions; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#57
  def topic_error_code; end

  # source://ruby-kafka//lib/kafka/protocol/metadata_response.rb#52
  def topic_name; end
end

# source://ruby-kafka//lib/kafka/protocol.rb#21
Kafka::Protocol::OFFSET_COMMIT_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#22
Kafka::Protocol::OFFSET_FETCH_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#5
class Kafka::Protocol::OffsetCommitRequest
  # source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#21
  def initialize(group_id:, generation_id:, member_id:, offsets:, retention_time: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#9
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#13
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#29
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#17
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/offset_commit_request.rb#7
Kafka::Protocol::OffsetCommitRequest::DEFAULT_RETENTION_TIME = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/offset_commit_response.rb#5
class Kafka::Protocol::OffsetCommitResponse
  # source://ruby-kafka//lib/kafka/protocol/offset_commit_response.rb#8
  def initialize(topics:); end

  # source://ruby-kafka//lib/kafka/protocol/offset_commit_response.rb#6
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/offset_commit_response.rb#12
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#5
class Kafka::Protocol::OffsetFetchRequest
  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#6
  def initialize(group_id:, topics:); end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#11
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#17
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#25
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_request.rb#21
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#5
class Kafka::Protocol::OffsetFetchResponse
  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#18
  def initialize(topics:); end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#22
  def offset_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#16
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#33
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#6
class Kafka::Protocol::OffsetFetchResponse::PartitionOffsetInfo
  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#9
  def initialize(offset:, metadata:, error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#7
  def metadata; end

  # source://ruby-kafka//lib/kafka/protocol/offset_fetch_response.rb#7
  def offset; end
end

# source://ruby-kafka//lib/kafka/protocol.rb#17
Kafka::Protocol::PRODUCE_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/produce_request.rb#29
class Kafka::Protocol::ProduceRequest
  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#37
  def initialize(required_acks:, timeout:, messages_for_topics:, transactional_id: T.unsafe(nil), compressor: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#45
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#49
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#32
  def compressor; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#65
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#32
  def messages_for_topics; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#32
  def required_acks; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#61
  def requires_acks?; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#53
  def response_class; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#32
  def timeout; end

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#32
  def transactional_id; end

  private

  # source://ruby-kafka//lib/kafka/protocol/produce_request.rb#85
  def compress(record_batch); end
end

# source://ruby-kafka//lib/kafka/protocol/produce_request.rb#30
Kafka::Protocol::ProduceRequest::API_MIN_VERSION = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/produce_response.rb#5
class Kafka::Protocol::ProduceResponse
  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#28
  def initialize(topics: T.unsafe(nil), throttle_time_ms: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#33
  def each_partition; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#26
  def throttle_time_ms; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#26
  def topics; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#41
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/produce_response.rb#15
class Kafka::Protocol::ProduceResponse::PartitionInfo
  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#18
  def initialize(partition:, error_code:, offset:, timestamp:); end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#16
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#16
  def offset; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#16
  def partition; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#16
  def timestamp; end
end

# source://ruby-kafka//lib/kafka/protocol/produce_response.rb#6
class Kafka::Protocol::ProduceResponse::TopicInfo
  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#9
  def initialize(topic:, partitions:); end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#7
  def partitions; end

  # source://ruby-kafka//lib/kafka/protocol/produce_response.rb#7
  def topic; end
end

# source://ruby-kafka//lib/kafka/protocol.rb#15
Kafka::Protocol::REPLICA_ID = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#135
Kafka::Protocol::RESOURCE_TYPES = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/protocol.rb#129
Kafka::Protocol::RESOURCE_TYPE_ANY = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#132
Kafka::Protocol::RESOURCE_TYPE_CLUSTER = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#134
Kafka::Protocol::RESOURCE_TYPE_DELEGATION_TOKEN = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#131
Kafka::Protocol::RESOURCE_TYPE_GROUP = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#130
Kafka::Protocol::RESOURCE_TYPE_TOPIC = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#133
Kafka::Protocol::RESOURCE_TYPE_TRANSACTIONAL_ID = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#128
Kafka::Protocol::RESOURCE_TYPE_UNKNOWN = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record.rb#3
class Kafka::Protocol::Record
  # source://ruby-kafka//lib/kafka/protocol/record.rb#7
  def initialize(value:, key: T.unsafe(nil), headers: T.unsafe(nil), attributes: T.unsafe(nil), offset_delta: T.unsafe(nil), offset: T.unsafe(nil), timestamp_delta: T.unsafe(nil), create_time: T.unsafe(nil), is_control_record: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#52
  def ==(other); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#4
  def attributes; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#4
  def bytesize; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def create_time; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def create_time=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#32
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#4
  def headers; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def is_control_record; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def is_control_record=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#4
  def key; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def offset; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def offset=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def offset_delta; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def offset_delta=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def timestamp_delta; end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#5
  def timestamp_delta=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record.rb#4
  def value; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/record.rb#59
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#7
class Kafka::Protocol::RecordBatch
  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#21
  def initialize(records: T.unsafe(nil), first_offset: T.unsafe(nil), first_timestamp: T.unsafe(nil), partition_leader_epoch: T.unsafe(nil), codec_id: T.unsafe(nil), in_transaction: T.unsafe(nil), is_control_batch: T.unsafe(nil), last_offset_delta: T.unsafe(nil), producer_id: T.unsafe(nil), producer_epoch: T.unsafe(nil), first_sequence: T.unsafe(nil), max_timestamp: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#140
  def ==(other); end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#64
  def attributes; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#19
  def codec_id; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#19
  def codec_id=(_arg0); end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#122
  def compressed?; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#70
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#113
  def encode_record_array; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#88
  def encode_record_batch_body; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def first_offset; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def first_sequence; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def first_timestamp; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#126
  def fulfill_relative_data; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def in_transaction; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def is_control_batch; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#60
  def last_offset; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def last_offset_delta; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#215
  def mark_control_record; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def max_timestamp; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def partition_leader_epoch; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def producer_epoch; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def producer_id; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#17
  def records; end

  # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#56
  def size; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/record_batch.rb#152
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#12
Kafka::Protocol::RecordBatch::CODEC_ID_MASK = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#13
Kafka::Protocol::RecordBatch::IN_TRANSACTION_MASK = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#14
Kafka::Protocol::RecordBatch::IS_CONTROL_BATCH_MASK = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#8
Kafka::Protocol::RecordBatch::MAGIC_BYTE = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#10
Kafka::Protocol::RecordBatch::RECORD_BATCH_OVERHEAD = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/record_batch.rb#15
Kafka::Protocol::RecordBatch::TIMESTAMP_TYPE_MASK = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/request_message.rb#5
class Kafka::Protocol::RequestMessage
  # source://ruby-kafka//lib/kafka/protocol/request_message.rb#8
  def initialize(api_key:, correlation_id:, client_id:, request:, api_version: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/request_message.rb#16
  def encode(encoder); end
end

# source://ruby-kafka//lib/kafka/protocol/request_message.rb#6
Kafka::Protocol::RequestMessage::API_VERSION = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#30
Kafka::Protocol::SASL_HANDSHAKE_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#27
Kafka::Protocol::SYNC_GROUP_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#9
class Kafka::Protocol::SaslHandshakeRequest
  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#13
  def initialize(mechanism); end

  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#20
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#28
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#24
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/sasl_handshake_request.rb#11
Kafka::Protocol::SaslHandshakeRequest::SUPPORTED_MECHANISMS = T.let(T.unsafe(nil), Array)

# source://ruby-kafka//lib/kafka/protocol/sasl_handshake_response.rb#10
class Kafka::Protocol::SaslHandshakeResponse
  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_response.rb#15
  def initialize(error_code:, enabled_mechanisms:); end

  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_response.rb#13
  def enabled_mechanisms; end

  # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_response.rb#11
  def error_code; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/sasl_handshake_response.rb#20
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/sync_group_request.rb#5
class Kafka::Protocol::SyncGroupRequest
  # source://ruby-kafka//lib/kafka/protocol/sync_group_request.rb#6
  def initialize(group_id:, generation_id:, member_id:, group_assignment: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/protocol/sync_group_request.rb#13
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/sync_group_request.rb#21
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/sync_group_request.rb#17
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/sync_group_response.rb#7
class Kafka::Protocol::SyncGroupResponse
  # source://ruby-kafka//lib/kafka/protocol/sync_group_response.rb#10
  def initialize(error_code:, member_assignment:); end

  # source://ruby-kafka//lib/kafka/protocol/sync_group_response.rb#8
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/sync_group_response.rb#8
  def member_assignment; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/sync_group_response.rb#15
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol.rb#20
Kafka::Protocol::TOPIC_METADATA_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol.rb#38
Kafka::Protocol::TXN_OFFSET_COMMIT_API = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#5
class Kafka::Protocol::TxnOffsetCommitRequest
  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#19
  def initialize(transactional_id:, group_id:, producer_id:, producer_epoch:, offsets:); end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#7
  def api_key; end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#11
  def api_version; end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#27
  def encode(encoder); end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_request.rb#15
  def response_class; end
end

# source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#5
class Kafka::Protocol::TxnOffsetCommitResponse
  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#26
  def initialize(errors:); end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#24
  def errors; end

  class << self
    # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#30
    def decode(decoder); end
  end
end

# source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#6
class Kafka::Protocol::TxnOffsetCommitResponse::PartitionError
  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#9
  def initialize(partition:, error_code:); end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#7
  def error_code; end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#7
  def partition; end
end

# source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#15
class Kafka::Protocol::TxnOffsetCommitResponse::TopicPartitionsError
  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#18
  def initialize(topic:, partitions:); end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#16
  def partitions; end

  # source://ruby-kafka//lib/kafka/protocol/txn_offset_commit_response.rb#16
  def topic; end
end

# source://ruby-kafka//lib/kafka.rb#25
class Kafka::ProtocolError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#179
class Kafka::RebalanceInProgress < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#131
class Kafka::RecordListTooLarge < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#81
class Kafka::ReplicaNotAvailable < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#71
class Kafka::RequestTimedOut < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/round_robin_assignment_strategy.rb#7
class Kafka::RoundRobinAssignmentStrategy
  # source://ruby-kafka//lib/kafka/round_robin_assignment_strategy.rb#21
  def call(cluster:, members:, partitions:); end

  # source://ruby-kafka//lib/kafka/round_robin_assignment_strategy.rb#8
  def protocol_name; end

  # source://ruby-kafka//lib/kafka/round_robin_assignment_strategy.rb#42
  def valid_sorted_partitions(members, partitions); end
end

# source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#14
class Kafka::SSLSocketWithTimeout
  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#24
  def initialize(host, port, ssl_context:, connect_timeout: T.unsafe(nil), timeout: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#162
  def close; end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#167
  def closed?; end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#93
  def read(num_bytes); end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#175
  def select_with_timeout(socket, type); end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#171
  def set_encoding(encoding); end

  # source://ruby-kafka//lib/kafka/ssl_socket_with_timeout.rb#127
  def write(bytes); end
end

# source://ruby-kafka//lib/kafka/sasl/plain.rb#4
module Kafka::Sasl; end

# source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#9
class Kafka::Sasl::AwsMskIam
  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#12
  def initialize(aws_region:, access_key_id:, secret_key_id:, logger:, session_token: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#30
  def authenticate!(host, encoder, decoder); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#26
  def configured?; end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#22
  def ident; end

  private

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#64
  def authentication_payload(host:, time_now:); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#56
  def bin_to_hex(s); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#103
  def canonical_headers(host:); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#89
  def canonical_query_string(time_now:); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#80
  def canonical_request(host:, time_now:); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#60
  def digest; end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#111
  def hashed_payload; end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#122
  def signature(host:, time_now:); end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#107
  def signed_headers; end

  # source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#115
  def string_to_sign(host:, time_now:); end
end

# source://ruby-kafka//lib/kafka/sasl/awsmskiam.rb#10
Kafka::Sasl::AwsMskIam::AWS_MSK_IAM = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/sasl/gssapi.rb#5
class Kafka::Sasl::Gssapi
  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#9
  def initialize(logger:, principal:, keytab:); end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#23
  def authenticate!(host, encoder, decoder); end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#15
  def configured?; end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#45
  def handshake_messages; end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#19
  def ident; end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#68
  def initialize_gssapi_context(host); end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#59
  def load_gssapi; end

  # source://ruby-kafka//lib/kafka/sasl/gssapi.rb#54
  def send_and_receive_sasl_token; end
end

# source://ruby-kafka//lib/kafka/sasl/gssapi.rb#7
Kafka::Sasl::Gssapi::GSSAPI_CONFIDENTIALITY = T.let(T.unsafe(nil), FalseClass)

# source://ruby-kafka//lib/kafka/sasl/gssapi.rb#6
Kafka::Sasl::Gssapi::GSSAPI_IDENT = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/sasl/oauth.rb#5
class Kafka::Sasl::OAuth
  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#21
  def initialize(logger:, token_provider:); end

  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#34
  def authenticate!(host, encoder, decoder); end

  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#30
  def configured?; end

  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#26
  def ident; end

  private

  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#53
  def initial_client_response; end

  # source://ruby-kafka//lib/kafka/sasl/oauth.rb#58
  def token_extensions; end
end

# source://ruby-kafka//lib/kafka/sasl/oauth.rb#6
Kafka::Sasl::OAuth::OAUTH_IDENT = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/sasl/plain.rb#5
class Kafka::Sasl::Plain
  # source://ruby-kafka//lib/kafka/sasl/plain.rb#8
  def initialize(logger:, authzid:, username:, password:); end

  # source://ruby-kafka//lib/kafka/sasl/plain.rb#23
  def authenticate!(host, encoder, decoder); end

  # source://ruby-kafka//lib/kafka/sasl/plain.rb#19
  def configured?; end

  # source://ruby-kafka//lib/kafka/sasl/plain.rb#15
  def ident; end
end

# source://ruby-kafka//lib/kafka/sasl/plain.rb#6
Kafka::Sasl::Plain::PLAIN_IDENT = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/sasl/scram.rb#8
class Kafka::Sasl::Scram
  # source://ruby-kafka//lib/kafka/sasl/scram.rb#14
  def initialize(username:, password:, logger:, mechanism: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#35
  def authenticate!(host, encoder, decoder); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#31
  def configured?; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#27
  def ident; end

  private

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#98
  def auth_message; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#106
  def client_key; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#126
  def client_proof; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#118
  def client_signature; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#164
  def digest; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#156
  def encoded_username; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#78
  def final_message; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#74
  def final_message_without_proof; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#66
  def first_message; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#70
  def first_message_bare; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#130
  def h(str); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#134
  def hi(str, salt, iterations); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#144
  def hmac(data, key); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#94
  def iterations; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#160
  def nonce; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#152
  def parse_response(data); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#86
  def rnonce; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#175
  def safe_str(val); end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#90
  def salt; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#102
  def salted_password; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#82
  def server_data; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#114
  def server_key; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#122
  def server_signature; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#110
  def stored_key; end

  # source://ruby-kafka//lib/kafka/sasl/scram.rb#148
  def xor(first, second); end
end

# source://ruby-kafka//lib/kafka/sasl/scram.rb#9
Kafka::Sasl::Scram::MECHANISMS = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/sasl_authenticator.rb#10
class Kafka::SaslAuthenticator
  # source://ruby-kafka//lib/kafka/sasl_authenticator.rb#11
  def initialize(logger:, sasl_gssapi_principal:, sasl_gssapi_keytab:, sasl_plain_authzid:, sasl_plain_username:, sasl_plain_password:, sasl_scram_username:, sasl_scram_password:, sasl_scram_mechanism:, sasl_oauth_token_provider:, sasl_aws_msk_iam_access_key_id:, sasl_aws_msk_iam_secret_key_id:, sasl_aws_msk_iam_aws_region:, sasl_aws_msk_iam_session_token: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/sasl_authenticator.rb#61
  def authenticate!(connection); end

  # source://ruby-kafka//lib/kafka/sasl_authenticator.rb#57
  def enabled?; end
end

# source://ruby-kafka//lib/kafka.rb#348
class Kafka::SaslScramError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/snappy_codec.rb#4
class Kafka::SnappyCodec
  # source://ruby-kafka//lib/kafka/snappy_codec.rb#5
  def codec_id; end

  # source://ruby-kafka//lib/kafka/snappy_codec.rb#20
  def compress(data); end

  # source://ruby-kafka//lib/kafka/snappy_codec.rb#24
  def decompress(data); end

  # source://ruby-kafka//lib/kafka/snappy_codec.rb#13
  def load; end

  # source://ruby-kafka//lib/kafka/snappy_codec.rb#9
  def produce_api_min_version; end
end

# source://ruby-kafka//lib/kafka/socket_with_timeout.rb#14
class Kafka::SocketWithTimeout
  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#23
  def initialize(host, port, connect_timeout: T.unsafe(nil), timeout: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#84
  def close; end

  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#88
  def closed?; end

  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#61
  def read(num_bytes); end

  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#92
  def set_encoding(encoding); end

  # source://ruby-kafka//lib/kafka/socket_with_timeout.rb#76
  def write(bytes); end
end

# source://ruby-kafka//lib/kafka/ssl_context.rb#6
module Kafka::SslContext
  class << self
    # source://ruby-kafka//lib/kafka/ssl_context.rb#9
    def build(ca_cert_file_path: T.unsafe(nil), ca_cert: T.unsafe(nil), client_cert: T.unsafe(nil), client_cert_key: T.unsafe(nil), client_cert_key_password: T.unsafe(nil), client_cert_chain: T.unsafe(nil), ca_certs_from_system: T.unsafe(nil), verify_hostname: T.unsafe(nil)); end
  end
end

# source://ruby-kafka//lib/kafka/ssl_context.rb#7
Kafka::SslContext::CLIENT_CERT_DELIMITER = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka.rb#93
class Kafka::StaleControllerEpoch < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/tagged_logger.rb#8
class Kafka::TaggedLogger < ::SimpleDelegator
  # source://ruby-kafka//lib/kafka/tagged_logger.rb#60
  def initialize(logger_or_stream = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#37
  def clear_tags!; end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#41
  def current_tags; end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#11
  def debug(msg_or_progname, &block); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#11
  def error(msg_or_progname, &block); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#71
  def flush; end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#11
  def info(msg_or_progname, &block); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#33
  def pop_tags(size = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#27
  def push_tags(*tags); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#20
  def tagged(*tags); end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#47
  def tags_text; end

  # source://ruby-kafka//lib/kafka/tagged_logger.rb#11
  def warn(msg_or_progname, &block); end

  class << self
    # source://ruby-kafka//lib/kafka/tagged_logger.rb#54
    def new(logger_or_stream = T.unsafe(nil)); end
  end
end

# source://ruby-kafka//lib/kafka.rb#355
class Kafka::TokenMethodNotImplementedError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka.rb#218
class Kafka::TopicAlreadyExists < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#188
class Kafka::TopicAuthorizationFailed < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#295
class Kafka::TransactionCoordinatorFencedError < ::Kafka::Error; end

# source://ruby-kafka//lib/kafka/transaction_manager.rb#6
class Kafka::TransactionManager
  # source://ruby-kafka//lib/kafka/transaction_manager.rb#13
  def initialize(cluster:, logger:, idempotent: T.unsafe(nil), transactional: T.unsafe(nil), transactional_id: T.unsafe(nil), transactional_timeout: T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#186
  def abort_transaction; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#94
  def add_partitions_to_transaction(topic_partitions); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#139
  def begin_transaction; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#267
  def close; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#153
  def commit_transaction; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#259
  def error?; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#39
  def idempotent?; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#255
  def in_transaction?; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#47
  def init_producer_id(force = T.unsafe(nil)); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#76
  def init_transactions; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#66
  def next_sequence_for(topic, partition); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#11
  def producer_epoch; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#11
  def producer_id; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#263
  def ready?; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#221
  def send_offsets_to_txn(offsets:, group_id:); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#43
  def transactional?; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#11
  def transactional_id; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#71
  def update_sequence_for(topic, partition, sequence); end

  private

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#301
  def complete_transaction; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#279
  def force_transactional!; end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#295
  def group_coordinator(group_id:); end

  # source://ruby-kafka//lib/kafka/transaction_manager.rb#289
  def transaction_coordinator; end
end

# source://ruby-kafka//lib/kafka/transaction_manager.rb#7
Kafka::TransactionManager::DEFAULT_TRANSACTION_TIMEOUT = T.let(T.unsafe(nil), Integer)

# source://ruby-kafka//lib/kafka/transaction_manager.rb#9
Kafka::TransactionManager::TRANSACTION_RESULT_ABORT = T.let(T.unsafe(nil), FalseClass)

# source://ruby-kafka//lib/kafka/transaction_manager.rb#8
Kafka::TransactionManager::TRANSACTION_RESULT_COMMIT = T.let(T.unsafe(nil), TrueClass)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#4
class Kafka::TransactionStateMachine
  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#27
  def initialize(logger:); end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#58
  def aborting_transaction?; end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#54
  def committing_transaction?; end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#62
  def error?; end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#50
  def in_transaction?; end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#46
  def ready?; end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#33
  def transition_to!(next_state); end

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#42
  def uninitialized?; end

  private

  # source://ruby-kafka//lib/kafka/transaction_state_machine.rb#68
  def in_state?(state); end
end

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#13
Kafka::TransactionStateMachine::ABORTING_TRANSACTION = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#12
Kafka::TransactionStateMachine::COMMITTING_TRANSACTION = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#14
Kafka::TransactionStateMachine::ERROR = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#11
Kafka::TransactionStateMachine::IN_TRANSACTION = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#6
class Kafka::TransactionStateMachine::InvalidStateError < ::StandardError; end

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#5
class Kafka::TransactionStateMachine::InvalidTransitionError < ::StandardError; end

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#10
Kafka::TransactionStateMachine::READY = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#8
Kafka::TransactionStateMachine::STATES = T.let(T.unsafe(nil), Array)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#17
Kafka::TransactionStateMachine::TRANSITIONS = T.let(T.unsafe(nil), Hash)

# source://ruby-kafka//lib/kafka/transaction_state_machine.rb#9
Kafka::TransactionStateMachine::UNINITIALIZED = T.let(T.unsafe(nil), Symbol)

# source://ruby-kafka//lib/kafka.rb#30
class Kafka::UnknownError < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#169
class Kafka::UnknownMemberId < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#46
class Kafka::UnknownTopicOrPartition < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#250
class Kafka::UnsupportedForMessageFormat < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#206
class Kafka::UnsupportedSaslMechanism < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka.rb#214
class Kafka::UnsupportedVersion < ::Kafka::ProtocolError; end

# source://ruby-kafka//lib/kafka/version.rb#4
Kafka::VERSION = T.let(T.unsafe(nil), String)

# source://ruby-kafka//lib/kafka/zstd_codec.rb#4
class Kafka::ZstdCodec
  # source://ruby-kafka//lib/kafka/zstd_codec.rb#5
  def codec_id; end

  # source://ruby-kafka//lib/kafka/zstd_codec.rb#19
  def compress(data); end

  # source://ruby-kafka//lib/kafka/zstd_codec.rb#23
  def decompress(data); end

  # source://ruby-kafka//lib/kafka/zstd_codec.rb#13
  def load; end

  # source://ruby-kafka//lib/kafka/zstd_codec.rb#9
  def produce_api_min_version; end
end
